{
 "metadata": {
  "name": "",
  "signature": "sha256:1a8915d103033424458430cd467eda82c8cdfe26b29672c486efffc72ecd48e5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Simplified initialization using lasagnemould"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook shows you how to initialize layers for nolearn.lasagne using lasagnemould. This makes initialization less verbose and more intuitive."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Table of contents:\n",
      "* [Old nolearn initialization](#The-old-nolearn-initialization-scheme)\n",
      "* [New nolearn initialization](#The-new-nolearn-initialization-scheme)\n",
      "* [Lasagnemould initialization](#Simple-layer-initialization-using-lasagnemould)\n",
      "* [Example: convolutional net](#Lasagnemould-with-conv-nets)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import OneHotEncoder"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nolearn.lasagne import NeuralNet\n",
      "from lasagne import layers\n",
      "from lasagne.nonlinearities import softmax\n",
      "from lasagne.updates import nesterov_momentum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('../../netz/data/mnist.csv', nrows=4000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = df.values[:, 0].astype(np.int32)\n",
      "X = df.values[:, 1:].astype(np.float32) / 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = (X - X.mean()) / X.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encoder = OneHotEncoder(sparse=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initialization possibilities"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The old nolearn initialization scheme"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers0 = [('input', layers.InputLayer),\n",
      "           ('dense', layers.DenseLayer),\n",
      "           ('output', layers.DenseLayer)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net0 = NeuralNet(\n",
      "    layers=layers0,\n",
      "\n",
      "    input_shape=(None, 784),\n",
      "    dense_num_units=100,\n",
      "    output_num_units=10,\n",
      "    output_nonlinearity=softmax,\n",
      "\n",
      "    update=nesterov_momentum,\n",
      "    update_learning_rate=0.01,\n",
      "\n",
      "    max_epochs=5,\n",
      "    verbose=1,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net0.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  input             \t(None, 784)         \tproduces     784 outputs\n",
        "  dense             \t(None, 100)         \tproduces     100 outputs\n",
        "  output            \t(None, 10)          \tproduces      10 outputs\n",
        "\n",
        " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
        "--------|--------------|--------------|---------------|-------------|-------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     1  |  \u001b[94m  1.241053\u001b[0m  |  \u001b[32m  0.529784\u001b[0m  |     2.342563  |     84.99%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2  |  \u001b[94m  0.411442\u001b[0m  |  \u001b[32m  0.418656\u001b[0m  |     0.982769  |     88.31%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3  |  \u001b[94m  0.294511\u001b[0m  |  \u001b[32m  0.376666\u001b[0m  |     0.781888  |     90.24%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4  |  \u001b[94m  0.236505\u001b[0m  |  \u001b[32m  0.354485\u001b[0m  |     0.667179  |     90.09%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     5  |  \u001b[94m  0.198799\u001b[0m  |  \u001b[32m  0.339423\u001b[0m  |     0.585697  |     90.84%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Anaconda\\lib\\site-packages\\lasagne-0.1dev-py2.7.egg\\lasagne\\init.py:30: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
        "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "NeuralNet(X_tensor_type=<function matrix at 0x0000000014A406D8>,\n",
        "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x0000000015253FD0>,\n",
        "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x0000000015253F98>,\n",
        "     dense_num_units=100, eval_size=0.2, input_shape=(None, 784),\n",
        "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dense', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
        "     loss=None, max_epochs=5, more_params={},\n",
        "     objective=<class 'lasagne.objectives.Objective'>,\n",
        "     objective_loss_function=<function categorical_crossentropy at 0x0000000014CAC278>,\n",
        "     on_epoch_finished=(), on_training_finished=(),\n",
        "     output_nonlinearity=<function softmax at 0x0000000015091208>,\n",
        "     output_num_units=10, regression=False,\n",
        "     update=<function nesterov_momentum at 0x000000001525C7B8>,\n",
        "     update_learning_rate=0.01, use_label_encoder=False, verbose=1,\n",
        "     y_tensor_type=TensorType(int32, vector))"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The new nolearn initialization scheme"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers1 = [(layers.InputLayer, {'shape': (None, 784)}),\n",
      "           (layers.DenseLayer, {'num_units': 100}),\n",
      "           (layers.DenseLayer, {'num_units': 10, 'nonlinearity': softmax})]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net1 = NeuralNet(\n",
      "    layers=layers1,\n",
      "\n",
      "    update=nesterov_momentum,\n",
      "    update_learning_rate=0.01,\n",
      "\n",
      "    max_epochs=5,\n",
      "    verbose=1,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net1.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  input0            \t(None, 784)         \tproduces     784 outputs\n",
        "  dense1            \t(None, 100)         \tproduces     100 outputs\n",
        "  dense2            \t(None, 10)          \tproduces      10 outputs\n",
        "\n",
        " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
        "--------|--------------|--------------|---------------|-------------|-------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     1  |  \u001b[94m  1.330435\u001b[0m  |  \u001b[32m  0.547794\u001b[0m  |     2.428711  |     84.65%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2  |  \u001b[94m  0.421414\u001b[0m  |  \u001b[32m  0.422659\u001b[0m  |     0.997054  |     88.06%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3  |  \u001b[94m  0.300310\u001b[0m  |  \u001b[32m  0.381731\u001b[0m  |     0.786705  |     90.53%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4  |  \u001b[94m  0.239421\u001b[0m  |  \u001b[32m  0.358076\u001b[0m  |     0.668632  |     90.37%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     5  |  \u001b[94m  0.200755\u001b[0m  |  \u001b[32m  0.345034\u001b[0m  |     0.581842  |     90.53%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "NeuralNet(X_tensor_type=<function matrix at 0x0000000014A406D8>,\n",
        "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x0000000015253FD0>,\n",
        "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x0000000015253F98>,\n",
        "     eval_size=0.2,\n",
        "     layers=[(<class 'lasagne.layers.input.InputLayer'>, {'shape': (None, 784), 'name': 'input0'}), (<class 'lasagne.layers.dense.DenseLayer'>, {'incoming': <lasagne.layers.input.InputLayer object at 0x00000000152EA128>, 'num_units': 100, 'name': 'dense1'}), (<class 'lasagne.layers.dense.DenseLayer'>, {'incoming': <lasagne.layers.dense.DenseLayer object at 0x000000001FBD22E8>, 'num_units': 10, 'nonlinearity': <function softmax at 0x0000000015091208>, 'name': 'dense2'})],\n",
        "     loss=None, max_epochs=5, more_params={},\n",
        "     objective=<class 'lasagne.objectives.Objective'>,\n",
        "     objective_loss_function=<function categorical_crossentropy at 0x0000000014CAC278>,\n",
        "     on_epoch_finished=(), on_training_finished=(), regression=False,\n",
        "     update=<function nesterov_momentum at 0x000000001525C7B8>,\n",
        "     update_learning_rate=0.01, use_label_encoder=False, verbose=1,\n",
        "     y_tensor_type=TensorType(int32, vector))"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Simple layer initialization using lasagnemould"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lasagnemould import layers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using hacks on lasagne and nolearn, lasagnemould allows layers to be initialized more easily. Just initialize them directly and omit the _incoming_ keyword that lasagne layers require. This circumvents the use of layer factories (nolearn) or having to initialize the layers one after the other (lasagne). And you can use \\*args with nolearn, not just \\*\\*kwargs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers2 = [layers.InputLayer(shape=(None, 784)),\n",
      "           layers.DenseLayer(100),\n",
      "           layers.DenseLayer(10, nonlinearity=softmax)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers.InputLayer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<lasagnemould.layers.InputLayer at 0x201ebb38>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net2 = NeuralNet(\n",
      "    layers=layers2,\n",
      "\n",
      "    update=nesterov_momentum,\n",
      "    update_learning_rate=0.01,\n",
      "\n",
      "    max_epochs=5,\n",
      "    verbose=1,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net2.initialize()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  input0            \t(None, 784)         \tproduces     784 outputs\n",
        "  dense1            \t(None, 100)         \tproduces     100 outputs\n",
        "  dense2            \t(None, 10)          \tproduces      10 outputs\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net2.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
        "--------|--------------|--------------|---------------|-------------|-------\n",
        "     1  |  \u001b[94m  1.295803\u001b[0m  |  \u001b[32m  0.548144\u001b[0m  |     2.363981  |     82.95%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2  |  \u001b[94m  0.413148\u001b[0m  |  \u001b[32m  0.410171\u001b[0m  |     1.007258  |     87.49%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3  |  \u001b[94m  0.287562\u001b[0m  |  \u001b[32m  0.373325\u001b[0m  |     0.770272  |     88.71%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4  |  \u001b[94m  0.229656\u001b[0m  |  \u001b[32m  0.351844\u001b[0m  |     0.652722  |     89.02%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     5  |  \u001b[94m  0.192333\u001b[0m  |  \u001b[32m  0.337078\u001b[0m  |     0.570588  |     89.49%  |  0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "NeuralNet(X_tensor_type=<function matrix at 0x0000000014A406D8>,\n",
        "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x0000000015253FD0>,\n",
        "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x0000000015253F98>,\n",
        "     eval_size=0.2,\n",
        "     layers=[<lasagnemould.layers.InputLayer object at 0x00000000201EBEF0>, <lasagnemould.layers.DenseLayer object at 0x00000000201EBF28>, <lasagnemould.layers.DenseLayer object at 0x00000000201EBF60>],\n",
        "     loss=None, max_epochs=5, more_params={},\n",
        "     objective=<class 'lasagne.objectives.Objective'>,\n",
        "     objective_loss_function=<function categorical_crossentropy at 0x0000000014CAC278>,\n",
        "     on_epoch_finished=(), on_training_finished=(), regression=False,\n",
        "     update=<function nesterov_momentum at 0x000000001525C7B8>,\n",
        "     update_learning_rate=0.01, use_label_encoder=False, verbose=1,\n",
        "     y_tensor_type=TensorType(int32, vector))"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lasagnemould with conv nets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lasagnemould.layers import InputLayer\n",
      "from lasagnemould.layers import Conv2DLayer\n",
      "from lasagnemould.layers import MaxPool2DLayer\n",
      "from lasagnemould.layers import DenseLayer\n",
      "from lasagnemould.layers import DropoutLayer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers3 = [\n",
      "    InputLayer(shape=(None, 1, 28, 28)),\n",
      "    Conv2DLayer(filter_size=(3, 3), num_filters=16),\n",
      "    MaxPool2DLayer(ds=(2, 2)),\n",
      "    Conv2DLayer(filter_size=(3, 3), num_filters=16),\n",
      "    MaxPool2DLayer(ds=(2, 2)),\n",
      "    DenseLayer(100),\n",
      "    DropoutLayer(),\n",
      "    DenseLayer(100),\n",
      "    DenseLayer(10, nonlinearity=softmax)\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net3 = NeuralNet(\n",
      "    layers=layers3,\n",
      "\n",
      "    update=nesterov_momentum,\n",
      "    update_learning_rate=0.01,\n",
      "\n",
      "    max_epochs=5,\n",
      "    verbose=1,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net3.fit(X_train.reshape(-1, 1, 28, 28), y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  input0            \t(None, 1, 28, 28)   \tproduces     784 outputs\n",
        "  conv2d1           \t(None, 16, 26, 26)  \tproduces   10816 outputs\n",
        "  maxpool2d2        \t(None, 16, 13, 13)  \tproduces    2704 outputs\n",
        "  conv2d3           \t(None, 16, 11, 11)  \tproduces    1936 outputs\n",
        "  maxpool2d4        \t(None, 16, 6, 6)    \tproduces     576 outputs\n",
        "  dense5            \t(None, 100)         \tproduces     100 outputs\n",
        "  dropout6          \t(None, 100)         \tproduces     100 outputs\n",
        "  dense7            \t(None, 100)         \tproduces     100 outputs\n",
        "  dense8            \t(None, 10)          \tproduces      10 outputs\n",
        "\n",
        " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
        "--------|--------------|--------------|---------------|-------------|-------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     1  |  \u001b[94m  2.251857\u001b[0m  |  \u001b[32m  2.049519\u001b[0m  |     1.098725  |     44.20%  |  6.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2  |  \u001b[94m  1.742610\u001b[0m  |  \u001b[32m  0.916728\u001b[0m  |     1.900903  |     72.70%  |  5.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3  |  \u001b[94m  0.975980\u001b[0m  |  \u001b[32m  0.527908\u001b[0m  |     1.848768  |     85.49%  |  5.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4  |  \u001b[94m  0.695324\u001b[0m  |  \u001b[32m  0.376072\u001b[0m  |     1.848910  |     89.96%  |  4.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     5  |  \u001b[94m  0.522164\u001b[0m  |  \u001b[32m  0.329344\u001b[0m  |     1.585469  |     91.27%  |  4.0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "NeuralNet(X_tensor_type=<function tensor4 at 0x0000000014A40A58>,\n",
        "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x0000000015253FD0>,\n",
        "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x0000000015253F98>,\n",
        "     eval_size=0.2,\n",
        "     layers=[<lasagnemould.layers.InputLayer object at 0x00000000207B3780>, <lasagnemould.layers.Conv2DLayer object at 0x00000000207B37B8>, <lasagnemould.layers.MaxPool2DLayer object at 0x00000000207B37F0>, <lasagnemould.layers.Conv2DLayer object at 0x00000000207B3828>, <lasagnemould.layers.MaxPool2DLaye...eLayer object at 0x00000000207B3908>, <lasagnemould.layers.DenseLayer object at 0x00000000207B3940>],\n",
        "     loss=None, max_epochs=5, more_params={},\n",
        "     objective=<class 'lasagne.objectives.Objective'>,\n",
        "     objective_loss_function=<function categorical_crossentropy at 0x0000000014CAC278>,\n",
        "     on_epoch_finished=(), on_training_finished=(), regression=False,\n",
        "     update=<function nesterov_momentum at 0x000000001525C7B8>,\n",
        "     update_learning_rate=0.01, use_label_encoder=False, verbose=1,\n",
        "     y_tensor_type=TensorType(int32, vector))"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}